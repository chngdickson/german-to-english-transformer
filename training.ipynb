{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982237cd-29a1-4e72-b0c6-6d445ea1fb9f",
   "metadata": {},
   "source": [
    "#### Download dataset, Takes a billion years~ Even if u run it the 2nd time.\n",
    "Please comment it, if u ran once once before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624132ef-5a72-4b46-a286-c313070a36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IWSLT2017\n",
    "train_data, valid_data, test_data = IWSLT2017(language_pair=('en','de'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b31b1-6ce8-4ed7-8a52-35880ca52e98",
   "metadata": {},
   "source": [
    "#### Load dataset, so we stored in pickle.\n",
    "If dataset is not loaded, Skil this line and reuse\n",
    "The reason is that pickle is much faster than Downloading the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c87c675-e19b-4b92-9f6a-19711b577352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables not loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def _load_dataset(filename):\n",
    "    with open(f'.data/{filename}.pkl', 'rb') as f:\n",
    "        train ,val, test = pickle.load(f)\n",
    "    return train, val, test\n",
    "\n",
    "try: \n",
    "    train_list, valid_list, test_list = _load_dataset('IWSLT2017_en_de')\n",
    "    print(\"variables loaded successfully!\")\n",
    "    # file Loaded\n",
    "except:\n",
    "    train_list, valid_list, test_list = list(train_data), list(valid_data), list(test_data)\n",
    "    train_copy, val_copy, test_copy = train_list.copy(), valid_list.copy(), test_list.copy() \n",
    "    print('Variables not loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266dc8d4-032b-4be6-8846-ca5ef421160f",
   "metadata": {},
   "source": [
    "#### Loading tokenizers\n",
    "Tokenizers are illustrated as just splitting the sentences \n",
    "\n",
    "YES It's different to trax.\n",
    "\n",
    "- [Hello, How are u] -> ['Hello' , ',' , 'how', 'are', 'u']\n",
    "- len = 1, len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e856f41a-dc2e-4ac4-a40e-0ff4a6aa48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\"\"\"Download these files in your shell\"\"\"\n",
    "#python -m spacy download de_dep_news_trf\n",
    "#python -m spacy download en_core_web_trf\n",
    "#python -m spacy download fr_dep_news_trf\n",
    "#python -m spacy download zh_core_web_trf\n",
    "dict_spacy = {'en':'en_core_web_trf', 'de':'de_dep_news_trf', 'fr':'fr_dep_news_trf', 'cn': 'zh_core_web_trf', \n",
    "             'cat': 'ca_core_news_trf'}\n",
    "\n",
    "\n",
    "# https://spacy.io/usage/models\n",
    "# english, german, french, chinese, catalan\n",
    "spacy_eng = spacy.load(dict_spacy['en'])\n",
    "spacy_ger = spacy.load(dict_spacy['de'])\n",
    "\n",
    "en_tokenizer = spacy_eng.tokenizer\n",
    "de_tokenizer = spacy_ger.tokenizer\n",
    "\n",
    "\n",
    "def _tokenize_en(sentence):\n",
    "    return [tok.text.lower() for tok in en_tokenizer(sentence)] \n",
    "def _tokenize_de(sentence):\n",
    "    return [tok.text.lower() for tok in de_tokenizer(sentence)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6038a-56aa-4f81-a4a2-86711c0873f8",
   "metadata": {},
   "source": [
    "#### Process for creating vocab\n",
    "Vocab is basically tokenize in trax\n",
    "It is a dictionary where it maps string to int vice versa\n",
    "- ['Hello', 'how' , 'are', 'u'] -> [342, 21, 64, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3153e8cc-c849-4b5e-a50c-134f74e35e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206112it [00:33, 6180.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_iter = iter(train_list)\n",
    "counter_en = Counter()\n",
    "counter_de = Counter()\n",
    "for (src, trg) in tqdm(train_iter):\n",
    "    counter_en.update(_tokenize_en(src)) # Update en for src\n",
    "    counter_de.update(_tokenize_de(trg)) # Update de for trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4facddea-7777-41af-901b-9f4168378425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab, OrderedDict, build_vocab_from_iterator\n",
    "\n",
    "vocab_en = vocab(OrderedDict(sorted(counter_en.items(), key=lambda x: x[1], reverse=True)),\n",
    "                min_freq=2\n",
    "                )\n",
    "vocab_de = vocab(OrderedDict(sorted(counter_de.items(), key=lambda x: x[1], reverse=True)),\n",
    "                min_freq=2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e85418-f1e7-4793-9150-6361086f47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_special_token(token: str, index:int, vocab:vocab):\n",
    "    if token not in vocab: vocab.insert_token(token, index)\n",
    "    return vocab\n",
    "\n",
    "special_tokens = ['<UNK>', '<BOS>', '<EOS>','<PAD>']\n",
    "for i , token in enumerate(special_tokens):\n",
    "    insert_special_token(token, i, vocab_en)\n",
    "    insert_special_token(token, i, vocab_de)\n",
    "    \n",
    "\n",
    "# If token not found, The default index should be.\n",
    "vocab_en.set_default_index(vocab_en['<UNK>'])\n",
    "vocab_de.set_default_index(vocab_de['<UNK>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8286a34-acf0-4c5c-a3ed-0ef86185814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Str to int\n",
      "src:  <'UNK'>: 0, <'BOS'> : 1, <'EOS'> 2, <'PAD'> 3\n",
      "trg:  <'UNK'>: 0, <'BOS'> : 1, <'EOS'> 2, <'PAD'> 3\n",
      "\n",
      "\n",
      "Int to str : <UNK>\n",
      "\n",
      "\n",
      "len of vocab\n",
      "src_vocab_len: 33667 , trg_vocab_len: 58554\n"
     ]
    }
   ],
   "source": [
    "# Str to int\n",
    "print('Str to int')\n",
    "print(f\"src:  <'UNK'>: {vocab_en['<UNK>']}, <'BOS'> : {vocab_en['<BOS>']}, <'EOS'> {vocab_en['<EOS>']}, <'PAD'> {vocab_en['<PAD>']}\")\n",
    "print(f\"trg:  <'UNK'>: {vocab_de['<UNK>']}, <'BOS'> : {vocab_de['<BOS>']}, <'EOS'> {vocab_de['<EOS>']}, <'PAD'> {vocab_de['<PAD>']}\")\n",
    "\n",
    "\n",
    "#Int to str\n",
    "print(f'\\n\\nInt to str : {vocab_en.lookup_token(0)}')\n",
    "\n",
    "\n",
    "# Len of vocab\n",
    "print('\\n\\nlen of vocab')\n",
    "print(f\"src_vocab_len: {len(vocab_en)} , trg_vocab_len: {len(vocab_de)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2d521-8246-4e85-8ab2-93d7deb2bfab",
   "metadata": {},
   "source": [
    "### Dumping Variables in Pickle\n",
    "Now that all the preprocessing is completed, we'll be dumping all the files into pickle as shown above.\n",
    "\n",
    "- Train, val , test of \"IWSLT2017_en_de\" dataset\n",
    "- vocab and tokenizers of en -> de [src -> trg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e55014c-081e-471a-95b0-3bd89e86daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def _store_dataset(filename,train, val, test):\n",
    "    with open(f'.data/{filename}.pkl', 'wb') as f:\n",
    "        pickle.dump([train,val,test], f)\n",
    "\n",
    "if not train_copy or not val_copy or not test_copy:\n",
    "    class MyException(Exception):\n",
    "        pass\n",
    "    raise MyException(f\"train_list is {train_list}. Please run this again \")\n",
    "        \n",
    "try: \n",
    "    _store_dataset(filename='IWSLT2017_en_de', train = train_copy, val = val_copy, test = test_copy)\n",
    "except Exception as e: \n",
    "    msg = 'Failed to store dataset: \\nif its ur 1st time running this, be warned \\n'+ str(e)\n",
    "    print(colored(msg, 'blue'))\n",
    "\n",
    "\n",
    "with open(f'.data/en_to_de_vocab_token.pkl', 'wb') as f:\n",
    "     pickle.dump([vocab_en, vocab_de, en_tokenizer, de_tokenizer], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b853dbe8-e4f3-4192-97cf-a9c6ca178fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to the text_transform: How are you\n",
      "output of the text_transform: [1, 68, 26, 16, 2]\n"
     ]
    }
   ],
   "source": [
    "src_transform = lambda x: [vocab_en['<BOS>']] + [vocab_en[token.text.lower()] for token in en_tokenizer(x)] + [vocab_en['<EOS>']]\n",
    "trg_transform = lambda x: [vocab_en['<BOS>']] + [vocab_de[token.text.lower()] for token in de_tokenizer(x)] + [vocab_en['<EOS>']]\n",
    "\n",
    "print(\"input to the text_transform:\", \"How are you\")\n",
    "print(\"output of the text_transform:\", src_transform(\"How are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6182efbd-7013-4dca-a57b-d225e053e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # A batch size of 8\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_list, trg_list = [], []\n",
    "    for (src, trg) in batch:\n",
    "        src_list.append(torch.tensor(src_transform(src)))\n",
    "        trg_list.append(torch.tensor(trg_transform(trg)))\n",
    "    return pad_sequence(src_list, padding_value=vocab_en['<PAD>']).cuda(), pad_sequence(trg_list, padding_value=vocab_de['<PAD>']).cuda()\n",
    "\n",
    "\n",
    "def batch_sampler(dataset:list):\n",
    "    indices = [(i, len(en_tokenizer(s[1]))) for i, s in enumerate(dataset)]\n",
    "    random.shuffle(indices)\n",
    "    pooled_indices = []\n",
    "    # create pool of indices with similar lengths \n",
    "    for i in range(0, len(indices), batch_size * 100):\n",
    "        pooled_indices.extend(sorted(indices[i:i + batch_size * 100], key=lambda x: x[1]))\n",
    "\n",
    "    pooled_indices = [x[0] for x in pooled_indices]\n",
    "\n",
    "    # yield indices for current batch\n",
    "    for i in range(0, len(pooled_indices), batch_size):\n",
    "        yield pooled_indices[i:i + batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d6dd5-531b-4a42-9229-2d0b6ee81d75",
   "metadata": {},
   "source": [
    "### Spawn Dataloaders\n",
    "Spawn dataloaders for train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c76c9d0-2624-41ef-b6ef-2e39dcff6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from seq_len_batch_sampler import BySequenceLengthSampler\n",
    "\n",
    "bucket_boundaries = [50,100,125,150,175,200,250,256]\n",
    "\n",
    "train_sampler = BySequenceLengthSampler(valid_list,de_tokenizer,bucket_boundaries, batch_size)\n",
    "val_sampler = BySequenceLengthSampler(valid_list,de_tokenizer,bucket_boundaries, batch_size)\n",
    "test_sampler = BySequenceLengthSampler(valid_list,de_tokenizer,bucket_boundaries, batch_size)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_list,\n",
    "                          collate_fn = collate_batch,\n",
    "                          batch_sampler=train_sampler, \n",
    "                          num_workers=0\n",
    "                         )\n",
    "valid_loader = DataLoader(valid_list,\n",
    "                          collate_fn = collate_batch,\n",
    "                          batch_sampler=val_sampler, \n",
    "                          num_workers=0\n",
    "                         )\n",
    "test_loader = DataLoader(test_list,\n",
    "                         collate_fn = collate_batch,\n",
    "                         batch_sampler=test_sampler, \n",
    "                         num_workers=0\n",
    "                        )\n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_list, batch_sampler = batch_sampler(train_list), collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(valid_list, batch_size=batch_size, collate_fn=collate_batch, drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test_list, batch_size=batch_size, collate_fn=collate_batch, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10fceeb2-0c9f-425e-af77-b019183e8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int to str\n",
    "def _detokenize_en(tokens):\n",
    "    return [vocab_en.lookup_token(token) for token in tokens]\n",
    "\n",
    "def _detokenize_de(tokens):\n",
    "    return [vocab_de.lookup_token(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5baed2d-8f65-451e-a81f-df8585c4ad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, 903, 260,   5,   2,   3,   3,   3,   3,   3,   3],\n",
      "       device='cuda:0')\n",
      "tensor([   1, 1234,  179,    6,    2,    3], device='cuda:0')\n",
      "['<BOS>', 'sex', '!', '\\n', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['<BOS>', 'sex', '!', '\\n', '<EOS>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "train_data_in_iter = next(iter(train_loader))\n",
    "src, trg = train_data_in_iter[0], train_data_in_iter[1]\n",
    "\n",
    "\n",
    "print(src[:,0])\n",
    "print(trg[:,0])\n",
    "print(_detokenize_en(src[:,0]))\n",
    "print(_detokenize_de(trg[:,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18588268-cdf9-4a9d-8808-d7d8e5bdbfed",
   "metadata": {},
   "source": [
    "#### Preprocessing before sending it to transformer\n",
    "We want to feed in [Batch_size, sentence_len] to our transformer, therefore it's better to transpose it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5c15d1-6293-48b4-b0ec-b85025b43b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transpose  \n",
      "src_shape torch.Size([11, 32]) \n",
      "trg_shape torch.Size([6, 32])\n",
      "\n",
      "\n",
      "After transposed  \n",
      "src_shape torch.Size([32, 11]) \n",
      "trg_shape torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "# We want to feed in \n",
    "# [batch_size, sentence] \n",
    "print(f\"Before transpose  \\nsrc_shape {src.shape} \\ntrg_shape {trg.shape}\")\n",
    "src_transposed = torch.transpose(src, dim0 = 1, dim1 = 0)\n",
    "trg_transposed = torch.transpose(trg, dim0 = 1, dim1 = 0)\n",
    "print(f\"\\n\\nAfter transposed  \\nsrc_shape {src_transposed.shape} \\ntrg_shape {trg_transposed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8faf7288-ee3c-41e4-8bfc-3f92d6f82b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, 903, 260,   5,   2,   3,   3,   3,   3,   3,   3],\n",
      "       device='cuda:0')\n",
      "tensor([   1, 1234,  179,    6,    2,    3], device='cuda:0')\n",
      "['<BOS>', 'sex', '!', '\\n', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['<BOS>', 'sex', '!', '\\n', '<EOS>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# Compare with above, Ensuring the transposed did it's job properly.\n",
    "print(src_transposed[0])\n",
    "print(trg_transposed[0])\n",
    "print(_detokenize_en(src_transposed[0]))\n",
    "print(_detokenize_de(trg_transposed[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5914c-e093-45a6-b242-882ec217510a",
   "metadata": {},
   "source": [
    "#### Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c44a26-30bf-4550-93d1-0e87ba8652e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BAD\n",
    "#del src, trg, src_transposed, trg_transposed\n",
    "#del train_data_in_iter\n",
    "#torch.cuda.empty_cache()\n",
    "#print(torch.cuda.memory_allocated())\n",
    "#print(torch.cuda.memory_reserved())\n",
    "\n",
    "\"\"\"Better\"\"\"\n",
    "src,trg = src.cpu(), trg.cpu()\n",
    "src_transposed,trg_transposed = src_transposed.cpu(),trg_transposed.cpu()\n",
    "del src, trg, src_transposed, trg_transposed\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed8812-dbf7-4e22-800c-4512b66d6b90",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b660793e-c440-4ec7-aff8-5309e5d25fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_transformer import Transformer\n",
    "import torch.nn as nn\n",
    "SRC_VOCAB_SIZE ,TRG_VOCAB_SIZE = len(vocab_en) , len(vocab_de)\n",
    "SRC_PAD_IDX, TRG_PAD_IDX = vocab_en['<PAD>'] , vocab_de['<PAD>']\n",
    "MAX_SENTENCE_LENGTH = 256\n",
    "EMBED_SIZE , NUM_LAYERS , FORWARD_EXPANSION , HEADS = 256, 3, 2 , 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_len=SRC_VOCAB_SIZE,\n",
    "    trg_vocab_len=TRG_VOCAB_SIZE,\n",
    "    src_pad_idx = SRC_PAD_IDX,\n",
    "    trg_pad_idx = TRG_PAD_IDX,\n",
    "    src_max_sentence_len = MAX_SENTENCE_LENGTH,\n",
    "    trg_max_sentence_len = MAX_SENTENCE_LENGTH,\n",
    "    hid_dim = EMBED_SIZE,\n",
    "    n_layers = NUM_LAYERS,\n",
    "    n_heads = HEADS,\n",
    "    ff_dim_multiplier = FORWARD_EXPANSION,\n",
    "    dropout = DROPOUT,\n",
    "    device = DEVICE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4faf9638-c101-489b-a968-268084344ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 42,741,690 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8e97fb5-b9c1-4d05-be55-b3a72ef96498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "#model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c293d8-3238-4639-9aac-3da7c84e5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b31ced-fe78-4561-853b-6137e6bea30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "    \n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    iterations = 0\n",
    "    for i, batch in tqdm(enumerate(iterator)):\n",
    "        src = torch.transpose(batch[0], dim0 = 1, dim1 = 0)\n",
    "        trg = torch.transpose(batch[1], dim0 = 1, dim1 = 0)\n",
    "        \n",
    "        # [sentence_len, batch_size]  -> [batch_size, sentence_len]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += float(loss)\n",
    "        iterations += 1\n",
    "        # The Concept is, rather than deleting them, it's better to send them back to CPU\n",
    "        # For properties that follow back propagation.\n",
    "        # For those that aren't included, we simply, delete them.\n",
    "        \"\"\"\"\n",
    "        Move all the back_prop gradients into cpu, \n",
    "        then delete them\"\"\"\n",
    "        src, trg = src.cpu(), trg.cpu()\n",
    "        loss, output = loss.cpu(), output.cpu()\n",
    "        del batch, src, trg, loss, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss / iterations\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    iterations = 0\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in tqdm(enumerate(iterator)):\n",
    "\n",
    "            src = torch.transpose(batch[0], dim0 = 1, dim1 = 0)\n",
    "            trg = torch.transpose(batch[1], dim0 = 1, dim1 = 0)\n",
    "            \n",
    "            # [sentence_len, batch_size]  -> [batch_size, sentence_len]\n",
    "            \n",
    "            output = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += float(loss)\n",
    "            iterations += 1\n",
    "            \n",
    "            \"\"\"Memory Management\"\"\"\n",
    "            src ,trg = src.cpu(),trg.cpu()\n",
    "            loss, output = loss.cpu(), output.cpu()\n",
    "            del batch, src, trg, loss, output\n",
    "            torch.cuda.empty_cache()\n",
    "    return epoch_loss / iterations\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50057f1-e67a-46b7-9c19-85979a43b7a5",
   "metadata": {},
   "source": [
    "#### Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44c61d0d-63d7-4cdf-90fa-09345e917d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_loaded_successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:06,  3.95it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.662 | Test PPL:  14.321 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6441it [18:36,  5.77it/s]\n",
      "27it [00:05,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 18m 42s\n",
      "\tTrain Loss: 1.757 | Train PPL:   5.796\n",
      "\t Val. Loss: 2.725 |  Val. PPL:  15.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loading a pretrained model, if you trained it before. \"\"\"\n",
    "try:\n",
    "    model.load_state_dict(torch.load('model_dicts/en_ger_attention_model.pt'))\n",
    "    print(\"model_loaded_successfully\")\n",
    "    \n",
    "    best_valid_loss = evaluate(model, iter(valid_loader), criterion)\n",
    "    print(f'| Test Loss: {best_valid_loss:.3f} | Test PPL: {math.exp(best_valid_loss):7.3f} |')\n",
    "    \n",
    "except:\n",
    "    print(\"Model not loaded with preset\")\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "\"\"\"Number of epochs is number of training iterations\"\"\"\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1    \n",
    "    \n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loader = DataLoader(train_list, batch_sampler = batch_sampler(train_list), collate_fn=collate_batch)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, iter(train_loader), optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, iter(valid_loader), criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'en_ger_attention_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28067d0f-f94b-49a4-99ea-51e7940477e8",
   "metadata": {},
   "source": [
    "#### Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4163a08b-9a04-4079-bd72-c4416d1423bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.670 | Test PPL:  14.444 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_dicts/en_ger_attention_model.pt'))\n",
    "test_loss = evaluate(model, iter(valid_loader), criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80ca3159-9f94-41c6-8ae4-63454897efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_tokenizer, src_vocab, trg_vocab, model, device,max_len = 50):\n",
    "    model.eval()\n",
    "    \n",
    "    src_tokens = ['<BOS>'] + [token.text.lower() for token in src_tokenizer(sentence)] + ['<EOS>']\n",
    "    src_indexes = [src_vocab[token] for token in src_tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = []\n",
    "    trg_indexes.append(trg_vocab['<BOS>'])\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor,trg_tensor)\n",
    "        \n",
    "        pred_token = output.cpu().argmax(2)[:,-1]\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_vocab['<EOS>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_vocab.lookup_token(i) for i in trg_indexes]\n",
    "    print(trg_tokens)\n",
    "    \"\"\"Memory Management\"\"\"\n",
    "    output = output.cpu()\n",
    "    del output\n",
    "    return trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7852440e-f042-4c83-afeb-d9ca3d6c6990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', 'schei√ü', 'ihre', 'mutter', 'an', '.', '\\n', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "translation = translate_sentence(sentence = \"Fuck your mother\",\n",
    "                                 src_tokenizer = en_tokenizer,\n",
    "                                 src_vocab = vocab_en, \n",
    "                                 trg_vocab = vocab_de,\n",
    "                                 model = model,\n",
    "                                 device = DEVICE,\n",
    "                                 max_len = 30\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
